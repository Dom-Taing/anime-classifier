{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c014af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from classifier import eval, naive_bayes as nb, naive_bayes_thres as nb_thres, preproc, logistic_regression as lg, LSTM\n",
    "from data import data\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99d99fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exists('data/myanimelist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76fc0cf",
   "metadata": {},
   "source": [
    "We write the data that we request from mynaimelist api and then we read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c4ab18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.write_data(100,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12a306c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/myanimelist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98158ca4",
   "metadata": {},
   "source": [
    "We split the data into train, dev and test data and then read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51a2cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split_data(dataset, 1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6bb31e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train_data.csv')\n",
    "test_data = pd.read_csv('data/test_data.csv')\n",
    "dev_data = pd.read_csv('data/dev_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3911de",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f291521",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [preproc.clean_para, preproc.bag_of_words, preproc.remove_stop_words]\n",
    "x_tr, y_tr = preproc.cleaning_data(train_data, func_list)\n",
    "x_dev, y_dev = preproc.cleaning_data(dev_data, func_list)\n",
    "x_te, y_te = preproc.cleaning_data(test_data, func_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a0cde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.logspace(-3,2,11)\n",
    "smoothing = nb.find_best_smoother(x_tr, y_tr, x_dev, y_dev, vals)\n",
    "weights = nb.calculating_weights(x_tr, y_tr, smoothing)\n",
    "genre_list = nb.get_label_count(y_tr)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c1b4896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.9972135352031107\n",
      "F_score : 0.9648815482148816\n"
     ]
    }
   ],
   "source": [
    "amount_list = nb.get_amount_list(y_tr)\n",
    "y_pred = nb.predict_all(x_tr, weights, genre_list, amount_list)\n",
    "\n",
    "y_pred = preproc.one_hot_encoding_label(y_pred, genre_list)\n",
    "y_tr = preproc.one_hot_encoding_label(y_tr, genre_list)\n",
    "acc = eval.accuracy(y_pred, y_tr)\n",
    "print(\"Training accuracy :\", acc)\n",
    "\n",
    "f_score = eval.f_score(y_pred, y_tr)\n",
    "print(\"F_score :\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5a3ec23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy : 0.9773333333333334\n",
      "F_score : 0.712059620596206\n"
     ]
    }
   ],
   "source": [
    "amount_list = nb.get_amount_list(y_dev)\n",
    "y_pred = nb.predict_all(x_dev, weights, genre_list, amount_list)\n",
    "\n",
    "y_pred = preproc.one_hot_encoding_label(y_pred, genre_list)\n",
    "y_dev = preproc.one_hot_encoding_label(y_dev, genre_list)\n",
    "acc = eval.accuracy(y_pred, y_dev)\n",
    "print(\"Validation accuracy :\", acc)\n",
    "\n",
    "f_score = eval.f_score(y_pred, y_dev)\n",
    "print(\"F_score :\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f380f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy : 0.9773733333333333\n",
      "F_score : 0.7165525304827125\n"
     ]
    }
   ],
   "source": [
    "amount_list = nb.get_amount_list(y_te)\n",
    "y_pred = nb.predict_all(x_te, weights, genre_list, amount_list)\n",
    "\n",
    "y_pred = preproc.one_hot_encoding_label(y_pred, genre_list)\n",
    "y_te = preproc.one_hot_encoding_label(y_te, genre_list)\n",
    "acc = eval.accuracy(y_pred, y_te)\n",
    "print(\"Testing accuracy :\", acc)\n",
    "\n",
    "f_score = eval.f_score(y_pred, y_te)\n",
    "print(\"F_score :\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8842418",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.save_weights(weights)\n",
    "weights = pd.read_csv('data/nb_weight.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442291fb",
   "metadata": {},
   "source": [
    "# Naive Bayes with threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "214f89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [preproc.clean_para, preproc.bag_of_words, preproc.remove_stop_words]\n",
    "x_tr, y_tr = preproc.cleaning_data(train_data, func_list)\n",
    "x_dev, y_dev = preproc.cleaning_data(dev_data, func_list)\n",
    "x_te, y_te = preproc.cleaning_data(test_data, func_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d43f1f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keochonodomtaing/Desktop/App/MyanimeList/classifier/naive_bayes_thres.py:75: RuntimeWarning: divide by zero encountered in log\n",
      "  if score[genre] - sent_prob >= np.log(threshold):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 0.5\n"
     ]
    }
   ],
   "source": [
    "smoothers = np.logspace(-3,2,11)\n",
    "thresholds = [0.1 * i for i in range(10)]\n",
    "\n",
    "smoothing, threshold = nb_thres.threshold_find_best_hyperparameter(x_tr, y_tr, x_dev, y_dev, smoothers, thresholds, 10)\n",
    "weights = nb.calculating_weights(x_tr, y_tr, smoothing)\n",
    "print(smoothing, threshold)\n",
    "\n",
    "count, total_number = nb_thres.total_word_count(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1f79298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.9949284355092248\n",
      "F_score : 0.9343865733307645\n"
     ]
    }
   ],
   "source": [
    "genre_list = nb.get_label_count(y_tr)[1]\n",
    "sentence_probabilites = nb_thres.find_sentence_probabilites(x_tr, count, total_number, smoothing)\n",
    "y_pred = nb_thres.threshold_predict_all(x_tr, sentence_probabilites, weights, genre_list, threshold)\n",
    "\n",
    "y_pred = preproc.one_hot_encoding_label(y_pred, genre_list)\n",
    "y_tr = preproc.one_hot_encoding_label(y_tr, genre_list)\n",
    "acc = eval.accuracy(y_pred, y_tr)\n",
    "print(\"Training accuracy :\", acc)\n",
    "\n",
    "f_score = eval.f_score(y_pred, y_tr)\n",
    "print(\"F_score :\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5915faee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy : 0.9764266666666667\n",
      "F_score : 0.6153176675369887\n"
     ]
    }
   ],
   "source": [
    "sentence_probabilites = nb_thres.find_sentence_probabilites(x_dev, count, total_number, smoothing)\n",
    "y_pred = nb_thres.threshold_predict_all(x_dev, sentence_probabilites, weights, genre_list, threshold)\n",
    "\n",
    "y_pred = preproc.one_hot_encoding_label(y_pred, genre_list)\n",
    "y_dev = preproc.one_hot_encoding_label(y_dev, genre_list)\n",
    "acc = eval.accuracy(y_pred, y_dev)\n",
    "print(\"Validation accuracy :\", acc)\n",
    "\n",
    "f_score = eval.f_score(y_pred, y_dev)\n",
    "print(\"F_score :\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c521f082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy : 0.9760133333333333\n",
      "F_score : 0.6101841820151679\n"
     ]
    }
   ],
   "source": [
    "sentence_probabilites = nb_thres.find_sentence_probabilites(x_te, count, total_number, smoothing)\n",
    "y_pred = nb_thres.threshold_predict_all(x_te, sentence_probabilites, weights, genre_list, threshold)\n",
    "\n",
    "y_pred = preproc.one_hot_encoding_label(y_pred, genre_list)\n",
    "y_te = preproc.one_hot_encoding_label(y_te, genre_list)\n",
    "acc = eval.accuracy(y_pred, y_te)\n",
    "print(\"Testing accuracy :\", acc)\n",
    "\n",
    "f_score = eval.f_score(y_pred, y_te)\n",
    "print(\"F_score :\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a8598d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'weight_thres.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m nb\u001b[38;5;241m.\u001b[39msave_weights(weights)\n\u001b[0;32m----> 2\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_thres.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weight_thres.csv'"
     ]
    }
   ],
   "source": [
    "nb.save_weights(weights, 'weight_thres.csv')\n",
    "weights = pd.read_csv('weight_thres.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1705e247",
   "metadata": {},
   "source": [
    "# Logistic Regression with Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f06b27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [preproc.clean_para, preproc.bag_of_words, preproc.remove_stop_words]\n",
    "x_tr, y_tr = preproc.cleaning_data(train_data, func_list)\n",
    "x_dev, y_dev = preproc.cleaning_data(dev_data, func_list)\n",
    "x_te, y_te = preproc.cleaning_data(test_data, func_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e4f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = nb.count_words(x_tr, y_tr)[1]\n",
    "genre_list = nb.get_label_count(y_tr)[1]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(len(vocab), len(genre_list), bias=True),\n",
    "        )\n",
    "model.add_module('softmax',torch.nn.LogSoftmax(dim=1))\n",
    "loss = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7f9492",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_num_genres = lg.make_num_genres(y_tr)\n",
    "X_tr = preproc.make_numpy_bag_of_word(x_tr, X_tr_num_genres, vocab)\n",
    "X_tr_var = Variable(torch.from_numpy(X_tr.astype(np.float32)))\n",
    "\n",
    "X_dev = preproc.make_numpy_bag_of_word(x_dev, [1 for i in range(len(x_dev))], vocab)\n",
    "X_dev_var = Variable(torch.from_numpy(X_dev.astype(np.float32)))\n",
    "\n",
    "X_te = preproc.make_numpy_bag_of_word(x_te, [1 for i in range(len(x_te))], vocab)\n",
    "X_te_var = Variable(torch.from_numpy(X_te.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4317404",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tr = lg.make_numpy_label(y_tr, genre_list)\n",
    "Y_dev = preproc.one_hot_encoding_label(y_dev, genre_list)\n",
    "Y_te = preproc.one_hot_encoding_label(y_te, genre_list)\n",
    "\n",
    "Y_tr_var = Variable(torch.from_numpy(Y_tr))\n",
    "Y_dev_var = Variable(torch.from_numpy(Y_dev))\n",
    "Y_te_var = Variable(torch.from_numpy(Y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c779c6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.96064\n",
      "Epoch 1: Dev F_score: 0\n",
      "Epoch 11: Dev Accuracy: 0.9610266666666667\n",
      "Epoch 11: Dev F_score: 0.02011397921555481\n",
      "Epoch 21: Dev Accuracy: 0.96204\n",
      "Epoch 21: Dev F_score: 0.07354376830458836\n",
      "Epoch 31: Dev Accuracy: 0.96324\n",
      "Epoch 31: Dev F_score: 0.1332914177931468\n",
      "Epoch 41: Dev Accuracy: 0.96408\n",
      "Epoch 41: Dev F_score: 0.17260442260442257\n",
      "Epoch 51: Dev Accuracy: 0.9647733333333334\n",
      "Epoch 51: Dev F_score: 0.2027761013880507\n",
      "Epoch 61: Dev Accuracy: 0.96536\n",
      "Epoch 61: Dev F_score: 0.22862232779097388\n",
      "Epoch 71: Dev Accuracy: 0.96584\n",
      "Epoch 71: Dev F_score: 0.2486803519061583\n",
      "Epoch 81: Dev Accuracy: 0.9662266666666667\n",
      "Epoch 81: Dev F_score: 0.2638767800058122\n",
      "Epoch 91: Dev Accuracy: 0.9666133333333333\n",
      "Epoch 91: Dev F_score: 0.27880184331797236\n"
     ]
    }
   ],
   "source": [
    "model_trained, losses, accuracies = lg.train_model(loss,model,\n",
    "                                                       X_tr_var,\n",
    "                                                       Y_tr_var,\n",
    "                                                       X_dv_var=X_dev_var,\n",
    "                                                       Y_dv_var = Y_dev_var,\n",
    "                                                       num_its=300,\n",
    "                                                       threshold = np.log(0.2),\n",
    "                                                       optim_args={'lr':1},\n",
    "                                                       param_file = \"lg_best.params\"\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ff72d",
   "metadata": {},
   "source": [
    "We'll try training the model with no duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b93efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(len(vocab), len(genre_list), bias=True),\n",
    "        )\n",
    "model.add_module('softmax',torch.nn.LogSoftmax(dim=1))\n",
    "loss = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cba20078",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [preproc.clean_para, preproc.bag_of_words, preproc.remove_stop_words]\n",
    "x_tr, y_tr = preproc.cleaning_data(train_data, func_list)\n",
    "x_dev, y_dev = preproc.cleaning_data(dev_data, func_list)\n",
    "x_te, y_te = preproc.cleaning_data(test_data, func_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45e1c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = preproc.make_numpy_bag_of_word(x_tr, [1 for i in range(len(x_tr))], vocab)\n",
    "X_tr_var = Variable(torch.from_numpy(X_tr.astype(np.float32)))\n",
    "\n",
    "X_dev = preproc.make_numpy_bag_of_word(x_dev, [1 for i in range(len(x_dev))], vocab)\n",
    "X_dev_var = Variable(torch.from_numpy(X_dev.astype(np.float32)))\n",
    "\n",
    "X_te = preproc.make_numpy_bag_of_word(x_te, [1 for i in range(len(x_te))], vocab)\n",
    "X_te_var = Variable(torch.from_numpy(X_te.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff201bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tr = lg.make_numpy_label(np.transpose([y_tr[:,0]]), genre_list)\n",
    "Y_dev = preproc.one_hot_encoding_label(y_dev, genre_list)\n",
    "Y_te = preproc.one_hot_encoding_label(y_te, genre_list)\n",
    "\n",
    "Y_tr_var = Variable(torch.from_numpy(Y_tr))\n",
    "Y_dev_var = Variable(torch.from_numpy(Y_dev))\n",
    "Y_te_var = Variable(torch.from_numpy(Y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e24e922c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.96064\n",
      "Epoch 1: Dev F_score: 0\n",
      "Epoch 11: Dev Accuracy: 0.96064\n",
      "Epoch 11: Dev F_score: 0.009395973154362415\n",
      "Epoch 21: Dev Accuracy: 0.9606666666666667\n",
      "Epoch 21: Dev F_score: 0.07057340894770006\n",
      "Epoch 31: Dev Accuracy: 0.9607866666666667\n",
      "Epoch 31: Dev F_score: 0.09812940815700706\n",
      "Epoch 41: Dev Accuracy: 0.96072\n",
      "Epoch 41: Dev F_score: 0.11158021712907117\n",
      "Epoch 51: Dev Accuracy: 0.96088\n",
      "Epoch 51: Dev F_score: 0.12417910447761196\n",
      "Epoch 61: Dev Accuracy: 0.9611466666666667\n",
      "Epoch 61: Dev F_score: 0.14041297935103242\n",
      "Epoch 71: Dev Accuracy: 0.96116\n",
      "Epoch 71: Dev F_score: 0.14749780509218616\n",
      "Epoch 81: Dev Accuracy: 0.9611466666666667\n",
      "Epoch 81: Dev F_score: 0.1533991865194654\n",
      "Epoch 91: Dev Accuracy: 0.96144\n",
      "Epoch 91: Dev F_score: 0.16991963260619977\n",
      "Epoch 101: Dev Accuracy: 0.96156\n",
      "Epoch 101: Dev F_score: 0.17605030008573877\n",
      "Epoch 111: Dev Accuracy: 0.9618\n",
      "Epoch 111: Dev F_score: 0.18584825234441602\n",
      "Epoch 121: Dev Accuracy: 0.9620266666666667\n",
      "Epoch 121: Dev F_score: 0.19729425028184894\n",
      "Epoch 131: Dev Accuracy: 0.9622266666666667\n",
      "Epoch 131: Dev F_score: 0.2075524475524476\n",
      "Epoch 141: Dev Accuracy: 0.9625066666666666\n",
      "Epoch 141: Dev F_score: 0.2201885745978924\n",
      "Epoch 151: Dev Accuracy: 0.9630133333333334\n",
      "Epoch 151: Dev F_score: 0.23707370737073707\n",
      "Epoch 161: Dev Accuracy: 0.96312\n",
      "Epoch 161: Dev F_score: 0.2421917808219178\n",
      "Epoch 171: Dev Accuracy: 0.96332\n",
      "Epoch 171: Dev F_score: 0.25507717303005684\n",
      "Epoch 181: Dev Accuracy: 0.9634933333333333\n",
      "Epoch 181: Dev F_score: 0.26318622174381057\n",
      "Epoch 191: Dev Accuracy: 0.9636666666666667\n",
      "Epoch 191: Dev F_score: 0.27119550682000537\n"
     ]
    }
   ],
   "source": [
    "model_trained, losses, accuracies = lg.train_model(loss,model,\n",
    "                                                       X_tr_var,\n",
    "                                                       Y_tr_var,\n",
    "                                                       X_dv_var=X_dev_var,\n",
    "                                                       Y_dv_var = Y_dev_var,\n",
    "                                                       num_its=200,\n",
    "                                                       threshold = np.log(0.2),\n",
    "                                                       optim_args={'lr':1},\n",
    "                                                      param_file = \"lg_1_best.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29367274",
   "metadata": {},
   "source": [
    "# LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3f6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [preproc.clean_para, preproc.sentence_to_list]\n",
    "x_tr, y_tr = preproc.cleaning_data(train_data, func_list)\n",
    "x_dev, y_dev = preproc.cleaning_data(dev_data, func_list)\n",
    "x_te, y_te = preproc.cleaning_data(test_data, func_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a7891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = nb.count_words(x_tr, y_tr)[1]\n",
    "genre_count, genre_list = nb.get_label_count(y_tr)\n",
    "word_to_index = LSTM.word_to_ix(vocab)\n",
    "\n",
    "embedding = LSTM.load_glove_vectors(vocab)\n",
    "loss_weight = LSTM.calculate_loss_weights(genre_count, genre_list)\n",
    "\n",
    "model = LSTM.BiLSTM(len(word_to_index), len(genre_list), 100, 128, embeddings=embedding)\n",
    "loss = torch.nn.BCELoss(reduction = \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b32d9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = [LSTM.prepare_sequence(x, word_to_index) for x in x_tr]\n",
    "# X_tr = biLSTM.create_x_numpy(X_tr, max_len).astype(int)\n",
    "# X_tr_var = Variable(torch.from_numpy(X_tr))\n",
    "\n",
    "X_dev = [LSTM.prepare_sequence(x, word_to_index) for x in x_dev]\n",
    "# X_dev = biLSTM.create_x_numpy(X_dev, max_len).astype(int)\n",
    "# X_dev_var = Variable(torch.from_numpy(X_dev))\n",
    "\n",
    "X_te = [LSTM.prepare_sequence(x, word_to_index) for x in x_te]\n",
    "# X_te = biLSTM.create_x_numpy(X_te, max_len).astype(int)\n",
    "# X_te_var = Variable(torch.from_numpy(X_te.astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3f7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tr = preproc.one_hot_encoding_label(y_tr, genre_list).astype(np.float32)\n",
    "Y_dev = preproc.one_hot_encoding_label(y_dev, genre_list).astype(np.float32)\n",
    "Y_te = preproc.one_hot_encoding_label(y_te, genre_list).astype(np.float32)\n",
    "\n",
    "Y_tr_var = Variable(torch.from_numpy(Y_tr))\n",
    "Y_dev_var = Variable(torch.from_numpy(Y_dev))\n",
    "Y_te_var = Variable(torch.from_numpy(Y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84516aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35439, 100)\n"
     ]
    }
   ],
   "source": [
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed329dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_tr)):\n",
    "    model(Variable(torch.Tensor(X_tr[i]).long()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e449443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.64788\n",
      "Epoch 1: Dev F_score: 0.06718236727773656\n",
      "Epoch 3: Dev Accuracy: 0.7478533333333334\n",
      "Epoch 3: Dev F_score: 0.07989101347735124\n",
      "Epoch 5: Dev Accuracy: 0.80204\n",
      "Epoch 5: Dev F_score: 0.08176139526253942\n",
      "Epoch 7: Dev Accuracy: 0.8369333333333333\n",
      "Epoch 7: Dev F_score: 0.0794821616739425\n",
      "Epoch 9: Dev Accuracy: 0.8820133333333333\n",
      "Epoch 9: Dev F_score: 0.08461777180097238\n",
      "Epoch 11: Dev Accuracy: 0.9215466666666666\n",
      "Epoch 11: Dev F_score: 0.09809932556713673\n",
      "Epoch 13: Dev Accuracy: 0.9338\n",
      "Epoch 13: Dev F_score: 0.09874750408422579\n",
      "Epoch 15: Dev Accuracy: 0.9384133333333333\n",
      "Epoch 15: Dev F_score: 0.08841523583974738\n",
      "Epoch 17: Dev Accuracy: 0.9398133333333333\n",
      "Epoch 17: Dev F_score: 0.08363784003248073\n",
      "Epoch 19: Dev Accuracy: 0.9432\n",
      "Epoch 19: Dev F_score: 0.08426483233018056\n"
     ]
    }
   ],
   "source": [
    "simple_loss_weight_001_model, losses, accuracies = LSTM.train_model(loss, model, X_tr, Y_tr, loss_weight, \n",
    "                                        X_dev, Y_dev, num_its=20, status_frequency=2, \n",
    "                                        optim_args = {'lr':0.01}, param_file = 'lstm.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cc1c069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.87384\n",
      "Epoch 1: Dev F_score: 0.22455335190952302\n",
      "Epoch 3: Dev Accuracy: 0.9417466666666666\n",
      "Epoch 3: Dev F_score: 0.26633081444164564\n",
      "Epoch 5: Dev Accuracy: 0.9418533333333333\n",
      "Epoch 5: Dev F_score: 0.2661955241460542\n",
      "Epoch 7: Dev Accuracy: 0.9574666666666667\n",
      "Epoch 7: Dev F_score: 0.19322205361659078\n",
      "Epoch 9: Dev Accuracy: 0.95748\n",
      "Epoch 9: Dev F_score: 0.19327093346825197\n",
      "Epoch 11: Dev Accuracy: 0.9574933333333333\n",
      "Epoch 11: Dev F_score: 0.1933198380566802\n",
      "Epoch 13: Dev Accuracy: 0.9574933333333333\n",
      "Epoch 13: Dev F_score: 0.1933198380566802\n",
      "Epoch 15: Dev Accuracy: 0.9574933333333333\n",
      "Epoch 15: Dev F_score: 0.1933198380566802\n",
      "Epoch 17: Dev Accuracy: 0.9574933333333333\n",
      "Epoch 17: Dev F_score: 0.1933198380566802\n",
      "Epoch 19: Dev Accuracy: 0.9574933333333333\n",
      "Epoch 19: Dev F_score: 0.1933198380566802\n"
     ]
    }
   ],
   "source": [
    "model = LSTM.BiLSTM(len(word_to_index), len(genre_list), 100, 128, embeddings=embedding)\n",
    "simple_loss_weight_01_model, losses, accuracies = LSTM.train_model(loss, model, X_tr, Y_tr, loss_weight, \n",
    "                                        X_dev, Y_dev, num_its=20, status_frequency=2, \n",
    "                                        optim_args = {'lr':0.1}, param_file = 'lstm.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ae9fccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.96064\n",
      "Epoch 1: Dev F_score: 0\n",
      "Epoch 3: Dev Accuracy: 0.96064\n",
      "Epoch 3: Dev F_score: 0\n",
      "Epoch 5: Dev Accuracy: 0.96064\n",
      "Epoch 5: Dev F_score: 0\n",
      "Epoch 7: Dev Accuracy: 0.96064\n",
      "Epoch 7: Dev F_score: 0\n",
      "Epoch 9: Dev Accuracy: 0.96064\n",
      "Epoch 9: Dev F_score: 0\n",
      "Epoch 11: Dev Accuracy: 0.9606533333333334\n",
      "Epoch 11: Dev F_score: 0.0006772773450728074\n",
      "Epoch 13: Dev Accuracy: 0.9606533333333334\n",
      "Epoch 13: Dev F_score: 0.0006772773450728074\n",
      "Epoch 15: Dev Accuracy: 0.9606533333333334\n",
      "Epoch 15: Dev F_score: 0.0006772773450728074\n",
      "Epoch 17: Dev Accuracy: 0.9606533333333334\n",
      "Epoch 17: Dev F_score: 0.0006772773450728074\n",
      "Epoch 19: Dev Accuracy: 0.9610266666666667\n",
      "Epoch 19: Dev F_score: 0.020770519262981575\n"
     ]
    }
   ],
   "source": [
    "model = LSTM.BiLSTM(len(word_to_index), len(genre_list), 100, 128, embeddings=embedding)\n",
    "loss_weight = torch.tensor([1 for i in range(len(genre_list))])\n",
    "no_loss_weight_model, losses, accuracies = LSTM.train_model(loss, model, X_tr, Y_tr,loss_weight, \n",
    "                                        X_dev, Y_dev, num_its=20, status_frequency=2, \n",
    "                                        optim_args = {'lr':0.01}, param_file = 'lstm_no_loss_weight.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d072a179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.96064\n",
      "Epoch 1: Dev F_score: 0\n",
      "Epoch 3: Dev Accuracy: 0.96036\n",
      "Epoch 3: Dev F_score: 0.05887939221272554\n",
      "Epoch 5: Dev Accuracy: 0.9606533333333334\n",
      "Epoch 5: Dev F_score: 0.08097165991902834\n",
      "Epoch 7: Dev Accuracy: 0.9612133333333334\n",
      "Epoch 7: Dev F_score: 0.037073816617014234\n",
      "Epoch 9: Dev Accuracy: 0.9637066666666667\n",
      "Epoch 9: Dev F_score: 0.2599238716693855\n",
      "Epoch 11: Dev Accuracy: 0.9651733333333333\n",
      "Epoch 11: Dev F_score: 0.32401656314699795\n",
      "Epoch 13: Dev Accuracy: 0.9655333333333334\n",
      "Epoch 13: Dev F_score: 0.3434086868173737\n",
      "Epoch 15: Dev Accuracy: 0.9662266666666667\n",
      "Epoch 15: Dev F_score: 0.3722428748451053\n",
      "Epoch 17: Dev Accuracy: 0.9671866666666666\n",
      "Epoch 17: Dev F_score: 0.4085556356645037\n",
      "Epoch 19: Dev Accuracy: 0.9674533333333334\n",
      "Epoch 19: Dev F_score: 0.3980271270036992\n"
     ]
    }
   ],
   "source": [
    "model = LSTM.BiLSTM(len(word_to_index), len(genre_list), 100, 128, embeddings=embedding)\n",
    "loss_weight = torch.tensor([1 for i in range(len(genre_list))])\n",
    "no_loss_weight_model, losses, accuracies = LSTM.train_model(loss, model, X_tr, Y_tr,loss_weight, \n",
    "                                        X_dev, Y_dev, num_its=20, status_frequency=2, \n",
    "                                        optim_args = {'lr':0.1}, param_file = 'lstm_no_loss_weight.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288ec3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCEloss_with_weight(output, target, w_p, w_n, genre_list):\n",
    "#     loss = \n",
    "#     for i in range(output.size(dim=0)):\n",
    "#         first_term = w_p[genre_list[i]] * target[i] * torch.log(output[i] + 1e-10)\n",
    "#         second_term = w_n[genre_list[i]] * (1 - target[i]) + torch.log(1 - output[i] + 1e-10)\n",
    "#         loss.append(first_term + second_term)\n",
    "    loss_func = torch.nn.BCELoss(reduction = \"none\")\n",
    "    first_term = target * w_p\n",
    "    second_term = (1 - target) * w_n\n",
    "    \n",
    "    loss = loss_func(output, target)\n",
    "    loss = (first_term + second_term) * loss\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c57e6e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_weights(genre_count, genre_list, num_data):\n",
    "    genre_list = sorted(genre_list)\n",
    "    positive_weights = [None] * len(genre_list)\n",
    "    negative_weights = [None] * len(genre_list)\n",
    "    \n",
    "    i = 0\n",
    "    for label in genre_list:\n",
    "        positive_weights[i] = num_data / (2 * genre_count[label])\n",
    "        negative_weights[i] = num_data / (2 * (num_data - genre_count[label]))\n",
    "        i += 1\n",
    "    return torch.tensor(positive_weights), torch.tensor(negative_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d93cae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_tr, Y_tr, w_p, w_n, genre_list, X_dv=None, Y_dv = None, num_its=50, status_frequency=10,\n",
    "               optim_args = {'lr':0.1},\n",
    "               param_file = 'best.params'):\n",
    "    \n",
    "    #initialize optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), **optim_args)\n",
    "    \n",
    "    losses=[]\n",
    "    accuracies=[]\n",
    "    \n",
    "    for epoch in range(num_its):\n",
    "        \n",
    "        model.train()\n",
    "        loss_value=0\n",
    "        count1=0\n",
    "        \n",
    "        for X,Y in zip(X_tr,Y_tr):\n",
    "            X_tr_var = Variable(torch.Tensor(X)).long()\n",
    "            Y_tr_var = Variable(torch.from_numpy(Y))\n",
    "            \n",
    "            y_pred = model(X_tr_var)\n",
    "            # set gradient to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = BCEloss_with_weight(y_pred, Y_tr_var, w_p, w_n, genre_list)\n",
    "            \n",
    "            output.backward()\n",
    "            optimizer.step()\n",
    "            loss_value += output.item()\n",
    "            count1+=1\n",
    "            \n",
    "            \n",
    "        losses.append(loss_value/count1)\n",
    "        \n",
    "        # write parameters if this is the best epoch yet\n",
    "        acc=0        \n",
    "        if X_dv is not None and Y_dv is not None:\n",
    "            acc=0\n",
    "            index=0\n",
    "            y_pred = np.zeros((Y_dv.shape[0],Y_dv.shape[1]))\n",
    "            for Xdv, Ydv in zip(X_dv, Y_dv):\n",
    "                \n",
    "                X_dv_var = Variable(torch.Tensor(Xdv)).long()\n",
    "                Y_dv_var = Variable(torch.from_numpy(Ydv))\n",
    "                # run forward on dev data\n",
    "                Y_hat = model(X_dv_var)\n",
    "                \n",
    "                # compute dev accuracy\n",
    "                for i in range(Y_hat.size(dim=0)):\n",
    "                    if Y_hat[i] >= 0.5:\n",
    "                        Y_hat[i] = 1\n",
    "                    else:\n",
    "                        Y_hat[i] = 0\n",
    "                y_pred[index] = Y_hat.tolist()\n",
    "                index += 1\n",
    "                # save\n",
    "            acc = eval.accuracy(y_pred, Y_dv)\n",
    "            f_score = eval.f_score(y_pred, Y_dv)\n",
    "            if len(accuracies) == 0 or acc > max(accuracies):\n",
    "                state = {'state_dict':model.state_dict(),\n",
    "                         'epoch':len(accuracies)+1,\n",
    "                         'accuracy':acc}\n",
    "                torch.save(state,param_file)\n",
    "            accuracies.append(acc)\n",
    "        # print status message if desired\n",
    "        if status_frequency > 0 and epoch % status_frequency == 0:\n",
    "            print(\"Epoch \"+str(epoch+1)+\": Dev Accuracy: \"+str(acc))\n",
    "            print(\"Epoch \"+str(epoch+1)+\": Dev F_score: \"+str(f_score))\n",
    "    return model, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d2c75fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.6150666666666667\n",
      "Epoch 1: Dev F_score: 0.09453017187303976\n",
      "Epoch 3: Dev Accuracy: 0.7319733333333334\n",
      "Epoch 3: Dev F_score: 0.12887848847287225\n",
      "Epoch 5: Dev Accuracy: 0.69116\n",
      "Epoch 5: Dev F_score: 0.13061592163044702\n",
      "Epoch 7: Dev Accuracy: 0.5692666666666667\n",
      "Epoch 7: Dev F_score: 0.11631151352682112\n",
      "Epoch 9: Dev Accuracy: 0.6109066666666667\n",
      "Epoch 9: Dev F_score: 0.1299344066785927\n",
      "Epoch 11: Dev Accuracy: 0.6203866666666666\n",
      "Epoch 11: Dev F_score: 0.13674539886601375\n",
      "Epoch 13: Dev Accuracy: 0.5720133333333334\n",
      "Epoch 13: Dev F_score: 0.12724652655047716\n",
      "Epoch 15: Dev Accuracy: 0.6259066666666666\n",
      "Epoch 15: Dev F_score: 0.1412261638762205\n",
      "Epoch 17: Dev Accuracy: 0.6493066666666667\n",
      "Epoch 17: Dev F_score: 0.14537301793605406\n",
      "Epoch 19: Dev Accuracy: 0.6231066666666667\n",
      "Epoch 19: Dev F_score: 0.13294070734026564\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    " \n",
    "model = LSTM.BiLSTM(len(word_to_index), len(genre_list), 100, 128, embeddings=embedding)\n",
    "genre_list = sorted(genre_list)\n",
    "w_p, w_n = calculate_loss_weights(genre_count, genre_list, len(X_tr))\n",
    "complex_loss_weight_001_model, losses, accuracies = train_model(model, X_tr, Y_tr, w_p, w_n, genre_list,\n",
    "                                        X_dev, Y_dev, num_its=20, status_frequency=2, \n",
    "                                        optim_args = {'lr':0.01}, param_file = 'lstm_complex_loss_weight.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa3bd4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.5843866666666667\n",
      "Epoch 1: Dev F_score: 0.10543836992394892\n",
      "Epoch 3: Dev Accuracy: 0.5592133333333333\n",
      "Epoch 3: Dev F_score: 0.12252156602521568\n",
      "Epoch 5: Dev Accuracy: 0.61288\n",
      "Epoch 5: Dev F_score: 0.13537820131030376\n",
      "Epoch 7: Dev Accuracy: 0.6896533333333333\n",
      "Epoch 7: Dev F_score: 0.16459694207163877\n",
      "Epoch 9: Dev Accuracy: 0.83664\n",
      "Epoch 9: Dev F_score: 0.26103739445114593\n",
      "Epoch 11: Dev Accuracy: 0.8728933333333333\n",
      "Epoch 11: Dev F_score: 0.3091528371621132\n",
      "Epoch 13: Dev Accuracy: 0.8956666666666667\n",
      "Epoch 13: Dev F_score: 0.35261024240919997\n",
      "Epoch 15: Dev Accuracy: 0.9205866666666667\n",
      "Epoch 15: Dev F_score: 0.4064181781941399\n",
      "Epoch 17: Dev Accuracy: 0.9283733333333334\n",
      "Epoch 17: Dev F_score: 0.4291179596174282\n",
      "Epoch 19: Dev Accuracy: 0.93516\n",
      "Epoch 19: Dev F_score: 0.46187894212681196\n",
      "Epoch 21: Dev Accuracy: 0.94608\n",
      "Epoch 21: Dev F_score: 0.5013563501849568\n",
      "Epoch 23: Dev Accuracy: 0.9471066666666667\n",
      "Epoch 23: Dev F_score: 0.502071043052592\n",
      "Epoch 25: Dev Accuracy: 0.9533066666666666\n",
      "Epoch 25: Dev F_score: 0.534432331826642\n",
      "Epoch 27: Dev Accuracy: 0.9587466666666666\n",
      "Epoch 27: Dev F_score: 0.5617563739376771\n",
      "Epoch 29: Dev Accuracy: 0.96136\n",
      "Epoch 29: Dev F_score: 0.5754468209786111\n",
      "Epoch 31: Dev Accuracy: 0.9506933333333333\n",
      "Epoch 31: Dev F_score: 0.5189906347554631\n",
      "Epoch 33: Dev Accuracy: 0.9598666666666666\n",
      "Epoch 33: Dev F_score: 0.5651545796012714\n",
      "Epoch 35: Dev Accuracy: 0.9649733333333333\n",
      "Epoch 35: Dev F_score: 0.5945361938570767\n",
      "Epoch 37: Dev Accuracy: 0.9503466666666667\n",
      "Epoch 37: Dev F_score: 0.5189873417721519\n",
      "Epoch 39: Dev Accuracy: 0.95788\n",
      "Epoch 39: Dev F_score: 0.5560084328882642\n",
      "Epoch 41: Dev Accuracy: 0.96528\n",
      "Epoch 41: Dev F_score: 0.5948973242065961\n",
      "Epoch 43: Dev Accuracy: 0.9677733333333334\n",
      "Epoch 43: Dev F_score: 0.6103498307270676\n",
      "Epoch 45: Dev Accuracy: 0.9693466666666667\n",
      "Epoch 45: Dev F_score: 0.6203137902559868\n",
      "Epoch 47: Dev Accuracy: 0.9701866666666666\n",
      "Epoch 47: Dev F_score: 0.625711416136592\n",
      "Epoch 49: Dev Accuracy: 0.9702666666666667\n",
      "Epoch 49: Dev F_score: 0.6269655403144864\n",
      "Epoch 51: Dev Accuracy: 0.9651333333333333\n",
      "Epoch 51: Dev F_score: 0.5908308558910969\n",
      "Epoch 53: Dev Accuracy: 0.9692533333333333\n",
      "Epoch 53: Dev F_score: 0.6205988812109245\n",
      "Epoch 55: Dev Accuracy: 0.9714266666666667\n",
      "Epoch 55: Dev F_score: 0.6364715860899066\n",
      "Epoch 57: Dev Accuracy: 0.9715333333333334\n",
      "Epoch 57: Dev F_score: 0.6372132540356839\n",
      "Epoch 59: Dev Accuracy: 0.9717466666666666\n",
      "Epoch 59: Dev F_score: 0.6369710467706015\n",
      "Epoch 61: Dev Accuracy: 0.9717866666666667\n",
      "Epoch 61: Dev F_score: 0.6369251887439945\n",
      "Epoch 63: Dev Accuracy: 0.9720133333333333\n",
      "Epoch 63: Dev F_score: 0.6379161635328618\n",
      "Epoch 65: Dev Accuracy: 0.97168\n",
      "Epoch 65: Dev F_score: 0.6349260914403575\n",
      "Epoch 67: Dev Accuracy: 0.97188\n",
      "Epoch 67: Dev F_score: 0.6355624675997925\n",
      "Epoch 69: Dev Accuracy: 0.9722666666666666\n",
      "Epoch 69: Dev F_score: 0.6396396396396395\n",
      "Epoch 71: Dev Accuracy: 0.95768\n",
      "Epoch 71: Dev F_score: 0.5495316491626455\n",
      "Epoch 73: Dev Accuracy: 0.96364\n",
      "Epoch 73: Dev F_score: 0.5828361633776962\n",
      "Epoch 75: Dev Accuracy: 0.96856\n",
      "Epoch 75: Dev F_score: 0.6153344208809135\n",
      "Epoch 77: Dev Accuracy: 0.9702266666666667\n",
      "Epoch 77: Dev F_score: 0.6262761506276151\n",
      "Epoch 79: Dev Accuracy: 0.97092\n",
      "Epoch 79: Dev F_score: 0.6297742318791377\n",
      "Epoch 81: Dev Accuracy: 0.9717466666666666\n",
      "Epoch 81: Dev F_score: 0.636846615252785\n",
      "Epoch 83: Dev Accuracy: 0.9721466666666667\n",
      "Epoch 83: Dev F_score: 0.640880178786316\n",
      "Epoch 85: Dev Accuracy: 0.9722933333333333\n",
      "Epoch 85: Dev F_score: 0.6416005519144533\n",
      "Epoch 87: Dev Accuracy: 0.9723333333333334\n",
      "Epoch 87: Dev F_score: 0.641932700603969\n",
      "Epoch 89: Dev Accuracy: 0.9723866666666666\n",
      "Epoch 89: Dev F_score: 0.6406385563074788\n",
      "Epoch 91: Dev Accuracy: 0.97252\n",
      "Epoch 91: Dev F_score: 0.6417521293238311\n",
      "Epoch 93: Dev Accuracy: 0.9725066666666666\n",
      "Epoch 93: Dev F_score: 0.6413913043478261\n",
      "Epoch 95: Dev Accuracy: 0.9723733333333333\n",
      "Epoch 95: Dev F_score: 0.640152830844043\n",
      "Epoch 97: Dev Accuracy: 0.9721466666666667\n",
      "Epoch 97: Dev F_score: 0.6392678293904334\n",
      "Epoch 99: Dev Accuracy: 0.9723866666666666\n",
      "Epoch 99: Dev F_score: 0.6402640264026402\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    " \n",
    "model = LSTM.BiLSTM(len(word_to_index), len(genre_list), 100, 128, embeddings=embedding)\n",
    "genre_list = sorted(genre_list)\n",
    "w_p, w_n = calculate_loss_weights(genre_count, genre_list, len(X_tr))\n",
    "complex_loss_weight_01_model, losses, accuracies = train_model(model, X_tr, Y_tr, w_p, w_n, genre_list,\n",
    "                                        X_dev, Y_dev, num_its=50, status_frequency=2, \n",
    "                                        optim_args = {'lr':0.1}, param_file = 'lstm_complex_loss_weight.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c109b456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.62884\n",
      "Epoch 1: Dev F_score: 0.11061056263778397\n",
      "Epoch 3: Dev Accuracy: 0.7149066666666667\n",
      "Epoch 3: Dev F_score: 0.13649947500201923\n",
      "Epoch 5: Dev Accuracy: 0.7619733333333333\n",
      "Epoch 5: Dev F_score: 0.15313092979127135\n",
      "Epoch 7: Dev Accuracy: 0.78772\n",
      "Epoch 7: Dev F_score: 0.168138356235958\n",
      "Epoch 9: Dev Accuracy: 0.8136133333333333\n",
      "Epoch 9: Dev F_score: 0.18408918461448667\n",
      "Epoch 11: Dev Accuracy: 0.8237733333333334\n",
      "Epoch 11: Dev F_score: 0.19638839910013983\n",
      "Epoch 13: Dev Accuracy: 0.8503466666666667\n",
      "Epoch 13: Dev F_score: 0.21914567969945736\n",
      "Epoch 15: Dev Accuracy: 0.8533333333333334\n",
      "Epoch 15: Dev F_score: 0.2082913487836476\n",
      "Epoch 17: Dev Accuracy: 0.8566133333333333\n",
      "Epoch 17: Dev F_score: 0.2106576629477393\n",
      "Epoch 19: Dev Accuracy: 0.86024\n",
      "Epoch 19: Dev F_score: 0.22032133293662604\n",
      "Epoch 21: Dev Accuracy: 0.8861866666666667\n",
      "Epoch 21: Dev F_score: 0.2550183278058998\n",
      "Epoch 23: Dev Accuracy: 0.8951333333333333\n",
      "Epoch 23: Dev F_score: 0.2501668414529507\n",
      "Epoch 25: Dev Accuracy: 0.8960266666666666\n",
      "Epoch 25: Dev F_score: 0.26834302871082755\n",
      "Epoch 27: Dev Accuracy: 0.9019866666666667\n",
      "Epoch 27: Dev F_score: 0.25949430845169735\n",
      "Epoch 29: Dev Accuracy: 0.9034533333333333\n",
      "Epoch 29: Dev F_score: 0.26449974606399185\n",
      "Epoch 31: Dev Accuracy: 0.90788\n",
      "Epoch 31: Dev F_score: 0.2785841077581706\n",
      "Epoch 33: Dev Accuracy: 0.9054666666666666\n",
      "Epoch 33: Dev F_score: 0.2729696472518458\n",
      "Epoch 35: Dev Accuracy: 0.90612\n",
      "Epoch 35: Dev F_score: 0.270589454055734\n",
      "Epoch 37: Dev Accuracy: 0.909\n",
      "Epoch 37: Dev F_score: 0.2718446601941748\n",
      "Epoch 39: Dev Accuracy: 0.9117066666666667\n",
      "Epoch 39: Dev F_score: 0.2572902646926873\n",
      "Epoch 41: Dev Accuracy: 0.91916\n",
      "Epoch 41: Dev F_score: 0.28375664500886005\n",
      "Epoch 43: Dev Accuracy: 0.9114266666666667\n",
      "Epoch 43: Dev F_score: 0.2877666988313498\n",
      "Epoch 45: Dev Accuracy: 0.9113066666666667\n",
      "Epoch 45: Dev F_score: 0.2873366188129419\n",
      "Epoch 47: Dev Accuracy: 0.9162133333333333\n",
      "Epoch 47: Dev F_score: 0.2937738817711845\n",
      "Epoch 49: Dev Accuracy: 0.9177333333333333\n",
      "Epoch 49: Dev F_score: 0.28851476014760147\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    " \n",
    "model = LSTM.BiLSTM(len(word_to_index), len(genre_list), 100, 128, embeddings=embedding)\n",
    "genre_list = sorted(genre_list)\n",
    "w_p, w_n = calculate_loss_weights(genre_count, genre_list, len(X_tr))\n",
    "complex_loss_weight_01_adam_model, losses, accuracies = train_model(model, X_tr, Y_tr, w_p, w_n, genre_list,\n",
    "                                        X_dev, Y_dev, num_its=50, status_frequency=2, \n",
    "                                        optim_args = {'lr':0.1}, param_file = 'lstm_adam_complex_loss_weight.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a13644c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, -1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d808353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35439 75 100 128\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'server'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(word_to_index), \u001b[38;5;28mlen\u001b[39m(genre_list), \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mserver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m server\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'server'"
     ]
    }
   ],
   "source": [
    "print(len(word_to_index), len(genre_list), 100, 128)\n",
    "from server import server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87f13e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9616)\n"
     ]
    }
   ],
   "source": [
    "acc=0\n",
    "count2=0\n",
    "for Xdv, Ydv in zip(X_te, Y_te):\n",
    "\n",
    "    X_dv_var = Variable(torch.Tensor(Xdv)).long()\n",
    "    Y_dv_var = Variable(torch.from_numpy(Ydv))\n",
    "    # run forward on dev data\n",
    "    Y_hat = model(X_dv_var)\n",
    "\n",
    "    # compute dev accuracy\n",
    "    for i in range(Y_hat.size(dim=0)):\n",
    "        if Y_hat[i] >= 0.5:\n",
    "            Y_hat[i] = 1\n",
    "        else:\n",
    "            Y_hat[i] = 0\n",
    "    acc += (Y_hat == Y_dv_var).float().sum()\n",
    "    count2 += Y_hat.size(dim=0)\n",
    "    # save\n",
    "acc/=count2\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "557395bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Drama' 'Historical' 'Romance' 'Slice of Life' nan nan nan nan nan nan\n",
      "  nan]\n",
      " ['Action' 'Comedy' 'Fantasy' 'Shounen' nan nan nan nan nan nan nan]\n",
      " ['Comedy' nan nan nan nan nan nan nan nan nan nan]\n",
      " ['Drama' 'Sci-Fi' nan nan nan nan nan nan nan nan nan]\n",
      " ['Comedy' 'Slice of Life' nan nan nan nan nan nan nan nan nan]\n",
      " ['Action' 'Fantasy' 'Historical' 'Martial Arts' 'Supernatural' nan nan\n",
      "  nan nan nan nan]\n",
      " ['Action' 'Adventure' 'Comedy' 'Fantasy' 'Kids' nan nan nan nan nan nan]\n",
      " ['Comedy' 'Romance' 'School' 'Shoujo' nan nan nan nan nan nan nan]\n",
      " ['Fantasy' 'Kids' 'Slice of Life' nan nan nan nan nan nan nan nan]\n",
      " ['Action' 'Adventure' 'Sci-Fi' nan nan nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "genre_list = sorted(genre_list)\n",
    "for i in range(10):\n",
    "    output = model(Variable(torch.Tensor(X_te[i]).long()))\n",
    "    for i in range(output.size(dim=0)):\n",
    "        if output[i] >= 0.5:\n",
    "            print(genre_list[i])\n",
    "            \n",
    "print(y_te[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2751955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.from_numpy(np.array([0.0,1.0,1.0,0.0]))\n",
    "y = torch.from_numpy(np.array([0,1,1,1]))\n",
    "(pred == y).float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "036ddf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8009, 387)\n",
      "(8009, 75)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape)\n",
    "print(Y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e849294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [26622 26598 21407 18062 18754     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "Y [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "X [10479 30475  5884 21407 30475 17176  5487  4366 30475  9103 21407  5033\n",
      " 14913 14219   557 28844 21407  8527 24565 30475 32655 21407 30475  3069\n",
      " 30475 28844 21407 24034 14913 20932  7559 30532 30475 23190 22424 17310\n",
      "  4264 34094 34560  1674  4257 18036  6087 30489 14493  5935 12695 23049\n",
      " 30475 25610 21407 16240 14219 30475  5487  3069 34560 12627 30475 31529\n",
      " 21407 30475 22636 18036 14913  9907 10849 22024 21407 30475 10169 14219\n",
      "   126 19796 12738 23017 30839 14716 34561  5684  4719   557 34554  2221\n",
      " 21218   194 31483 12627 27042 22024 31209 24034 14219 30475 25710  6336\n",
      "  8314 30839 30475 17072 21407 11350  4424 21407 25133 30839 30475 14284\n",
      " 30633 18036 28133 29330 30469 34560 29909  5685 13639  4923 15234 34561\n",
      " 12311 32849 14594  2308 30551 11946 30839 31529  8423 21946  8357 30475\n",
      "  5487  3069 34560 21171   685 15234  2308 13284 24996 30475 34554 10533\n",
      " 25214   557 19018 12314  1019  5303 33499 15235  2221 33499 31487 24106\n",
      "  3989 14219 30475 27117 30475 14700 29148 21407 24034 14913 21650  5822\n",
      " 11019 30532  2152 21650 31735 18965 34560 10050 12738  4383 24875 21573\n",
      "  3431   557 11348 33367  5694   351 18965  1674 33843 30475 17270 21407\n",
      " 30475 10054 33843 10527     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "Y [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "X [30475  8731 18933 21407 27714   665 29159  6274  6087 30489  5796  6939\n",
      "  1888  6274 23504 19578 27497  5302  6762  1049 32644 15591 27417  8423\n",
      " 10175 31054  1674 20272 30839 31440 30475 21946 14747  5919 30489 25628\n",
      " 17873 15591 29150 33511 30475 29098  5932 21407 12916 33181 32309  9852\n",
      " 24467  1049 12916  5567  7104  7199  2308 27206 33039 30839 27497  1674\n",
      " 30475 25144 21407 12916 10816  6274 31400 34415 14934 29315 31933 30475\n",
      " 33248 21407 13284 13491  6564 21573 31551 16760   557 23251 32292 33367\n",
      " 12899 30839 14601   557 20726  5924 14219 13140 19224 13983 30475 20731\n",
      " 29159  6274 18930 12018  5412 30839 30475 25763 14934 33341 29127 30839\n",
      " 22119 12916 22181  2630 19822  5519 17873 11019  3649  2508 27714   658\n",
      " 30475 29159  6274 21429  8150 30489 22083 10804 14747 14309  5659  5940\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "Y [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "X [11697  6720 25589 33078 16471  2308 30475 22947 16240 30475 29138  1674\n",
      " 19895 14381  3279 30839 12688 26020 30475 11838 17560 30475  4454  1674\n",
      "  9492 21407 25589  4264 30475 33630 11792  4073   557  4797 30685 30475\n",
      " 33630 13284 17185 33605  3211 13284  6979 25252 30475  9525 21407 30475\n",
      " 11912 31397 14219 30475 33630 21592 22871 14985 33078 30599 25257 30469\n",
      "  4073   609 30475 11838  1060 21407 22949 18965 33367  8208 21407 10221\n",
      " 21592 22875 23734  1650 32125  1638 21407 25351  1674  9836 24124 23308\n",
      " 30475 22927 21407 11602  1674 30475 30825 21407 30475 22947 16254 19751\n",
      "  6720 17951   557   124  3893 33367  7127 34259 28789  7132 21407   557\n",
      " 22947 24339 30464 30475 23251 22732 21407   557 33383 12536 31057 22947\n",
      " 24301 32706 10518 10977 17952 24450 10518  3279   557 22947 14913 21592\n",
      " 21407 23944 33572 30475 30617 21407  1650  9475   927 30469 17279 13140\n",
      " 30839 14756 22635  1674 31825 30475 23733 31397 10479 14219 30475 10515\n",
      " 21407 13284  5005 12953 17951  1674 13284  6468 31372   771 30475 11838\n",
      " 17560  9594  6412   933 32250  6848 20193  1674  3094 29133  8945  1402\n",
      " 14219 21825 30839 24370 30475 19895  6354 21407  1402 10635 22876  4264\n",
      " 18299 25322     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "Y [1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n",
      "X [ 6231 23192 10778 20487  1674 21946 33037 10533  6024 15197 30475 30567\n",
      " 32573 21407 22559  3410 20625  6299 21925  1674 33313 14219 28633 21407\n",
      " 30489 23098 24958 28710  1674 18623 21407  7749 31721 10947  6819 19473\n",
      " 21592  1019  1846 14219 30475 13485 30469 20932  5002 33419 12688 30839\n",
      "  9587 30475 13534 21407 33030 30475  4234 21926  5250 21407  3363 31721\n",
      "  8023 30475  1377 21407 17759 10574  1650  9277 23868 13639 13284 31516\n",
      " 14661 14913 30839 11270 14643 21573 23730 23191  8022  7370 33367 21650\n",
      "  2013 24324 14219 23886  2508 13284 28363 26449 30475 23515  8542   658\n",
      "  9015 30475 12888 21407 32135  5250 12337  5366 34160  3991 30839   773\n",
      "  2308 13284 33402  1674   894 30475  6642 27993 21891  1915  2308 13284\n",
      "  6892 17759  8875 13284 18623 23002 12738 33419  9037  1915 14219  8542\n",
      "   658 33334 17759 13494 27206 33419  9454  1674 11546 13140 30475 21769\n",
      " 30839 18841  8022 33515  2231 29598 32033 10518 17759  9341   557 18334\n",
      " 21407 13284 29959 12627 31487 23063 30475 10185 21407   557 17904  9972\n",
      "  1674 13764  1674 15494 17526 17759 14913 13040 13284 31516 13897 34177\n",
      " 14913  1650 31949  2404 16471  2308 30609 23581  1916  9259 33367  4383\n",
      " 24381 22640 19320 20932 23017 30839  7701 30489 22181 26641  8650  1514\n",
      " 30599 22868  9852 14913 10660 21573  7032 30475 10575 11817  5654 30839\n",
      " 31961 30469 30475 17873 30551 27185 10518 21592  1846 31526  1402  8746\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0]\n",
      "Y [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6be44b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comedy\n",
      "['Mecha' 'Parody' 'Slice of Life' nan nan nan nan nan nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "output = model(Variable(torch.tensor(X_dev[375])))\n",
    "genre_list = sorted(genre_list)\n",
    "for i in range(output.size(dim=0)):\n",
    "    if output[i] >= 0.5:\n",
    "        print(genre_list[i])\n",
    "print(y_dev[375])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf4efa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m((y_pred \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39mmean())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0226fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c7ce323",
   "metadata": {},
   "source": [
    "# Logistic Regression with 1 label per synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9821f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [preproc.clean_para, preproc.bag_of_words, preproc.remove_stop_words]\n",
    "x_tr, y_tr = preproc.cleaning_data(train_data, func_list)\n",
    "x_dev, y_dev = preproc.cleaning_data(dev_data, func_list)\n",
    "x_te, y_te = preproc.cleaning_data(test_data, func_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0abf9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = nb.count_words(x_tr, y_tr)[1]\n",
    "genre_list = nb.get_label_count(y_tr)[1]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(len(vocab), len(genre_list), bias=True),\n",
    "        )\n",
    "model.add_module('softmax',torch.nn.LogSoftmax(dim=1))\n",
    "loss = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f38d9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = preproc.make_numpy_bag_of_word(x_tr, [1 for i in range(len(x_tr))], vocab)\n",
    "X_tr_var = Variable(torch.from_numpy(X_tr.astype(np.float32)))\n",
    "\n",
    "X_dev = preproc.make_numpy_bag_of_word(x_dev, [1 for i in range(len(x_dev))], vocab)\n",
    "X_dev_var = Variable(torch.from_numpy(X_dev.astype(np.float32)))\n",
    "\n",
    "X_te = preproc.make_numpy_bag_of_word(x_te, [1 for i in range(len(x_te))], vocab)\n",
    "X_te_var = Variable(torch.from_numpy(X_te.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aedfa86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tr = lg.make_numpy_label([y_tr[:,0]], genre_list)\n",
    "Y_dev = preproc.one_hot_encoding_label(y_dev, genre_list)\n",
    "Y_te = preproc.one_hot_encoding_label(y_te, genre_list)\n",
    "\n",
    "Y_tr_var = Variable(torch.from_numpy(Y_tr))\n",
    "Y_dev_var = Variable(torch.from_numpy(Y_dev))\n",
    "Y_te_var = Variable(torch.from_numpy(Y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d41dd539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8009, 34675) (8009,)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape, Y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4e79e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.018\n",
      "Epoch 11: Dev Accuracy: 0.34\n",
      "Epoch 21: Dev Accuracy: 0.331\n",
      "Epoch 31: Dev Accuracy: 0.378\n",
      "Epoch 41: Dev Accuracy: 0.404\n",
      "Epoch 51: Dev Accuracy: 0.42\n",
      "Epoch 61: Dev Accuracy: 0.439\n",
      "Epoch 71: Dev Accuracy: 0.449\n",
      "Epoch 81: Dev Accuracy: 0.454\n",
      "Epoch 91: Dev Accuracy: 0.455\n",
      "Epoch 101: Dev Accuracy: 0.476\n",
      "Epoch 111: Dev Accuracy: 0.505\n",
      "Epoch 121: Dev Accuracy: 0.53\n",
      "Epoch 131: Dev Accuracy: 0.528\n",
      "Epoch 141: Dev Accuracy: 0.516\n",
      "Epoch 151: Dev Accuracy: 0.53\n",
      "Epoch 161: Dev Accuracy: 0.536\n",
      "Epoch 171: Dev Accuracy: 0.529\n",
      "Epoch 181: Dev Accuracy: 0.546\n",
      "Epoch 191: Dev Accuracy: 0.548\n"
     ]
    }
   ],
   "source": [
    "model_trained, losses, accuracies = lg.train_1_label_model(loss,model,\n",
    "                                                       X_tr_var,\n",
    "                                                       Y_tr_var,\n",
    "                                                       X_dv_var=X_dev_var,\n",
    "                                                       Y_dv_var = Y_dev_var,\n",
    "                                                       num_its=200,\n",
    "                                                       optim_args={'lr':0.01, 'momentum': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccfa9402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.098\n"
     ]
    }
   ],
   "source": [
    "Y_dev = lg.make_bi_numpy_label(y_dev, genre_list)\n",
    "Y_dev_var = Variable(torch.from_numpy(Y_dev))\n",
    "Y_hat = model.forward(X_dev_var).data\n",
    "acc = lg.accuracy(Y_hat.data.numpy(),Y_dev_var.data.numpy(), np.log(0.4))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c8a9115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Dev Accuracy: 0.0\n",
      "Epoch 11: Dev Accuracy: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m,torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLogSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mNLLLoss()\n\u001b[0;32m----> 6\u001b[0m model_trained, losses, accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mlg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mX_tr_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mY_tr_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mX_dv_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_dev_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mY_dv_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY_dev_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mnum_its\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43moptim_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/App/MyanimeList/classifier/logistic_regression.py:134\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(loss, model, X_tr_var, Y_tr_var, num_its, threshold, X_dv_var, Y_dv_var, status_frequency, optim_args, param_file)\u001b[0m\n\u001b[1;32m    132\u001b[0m output \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mforward(model\u001b[38;5;241m.\u001b[39mforward(X_tr_var),Y_tr_var)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# backpropagate and train\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    137\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(output\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(len(vocab), len(genre_list), bias=True),\n",
    "        )\n",
    "model.add_module('softmax',torch.nn.LogSoftmax(dim=1))\n",
    "loss = torch.nn.NLLLoss()\n",
    "\n",
    "\n",
    "model_trained, losses, accuracies = lg.train_model(loss,model,\n",
    "                                                   X_tr_var,\n",
    "                                                   Y_tr_var,\n",
    "                                                   X_dv_var=X_dev_var,\n",
    "                                                   Y_dv_var = Y_dev_var,\n",
    "                                                   num_its=200,\n",
    "                                                   threshold=np.log(0.2),\n",
    "                                                   optim_args={'lr':0.01, 'momentum': 1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
